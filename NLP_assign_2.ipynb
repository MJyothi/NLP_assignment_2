{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41ff63bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\vanam\\anaconda3\\lib\\site-packages (3.6.1)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vanam\\anaconda3\\lib\\site-packages (from nltk) (4.59.0)\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2022.3.2-cp38-cp38-win_amd64.whl (274 kB)\n",
      "Requirement already satisfied: click in c:\\users\\vanam\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\vanam\\anaconda3\\lib\\site-packages (from nltk) (1.0.1)\n",
      "Installing collected packages: regex, nltk\n",
      "  Attempting uninstall: regex\n",
      "    Found existing installation: regex 2021.4.4\n",
      "    Uninstalling regex-2021.4.4:\n",
      "      Successfully uninstalled regex-2021.4.4\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.6.1\n",
      "    Uninstalling nltk-3.6.1:\n",
      "      Successfully uninstalled nltk-3.6.1\n",
      "Successfully installed nltk-3.7 regex-2022.3.2\n",
      "Requirement already satisfied: pytrec-eval-terrier in c:\\users\\vanam\\anaconda3\\lib\\site-packages (0.5.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U nltk\n",
    "!pip install pytrec-eval-terrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "508e6b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from nltk.util import pad_sequence\n",
    "from nltk.util import bigrams\n",
    "from nltk.util import ngrams\n",
    "from nltk.util import everygrams\n",
    "from nltk.lm.preprocessing import pad_both_ends\n",
    "from nltk.lm.preprocessing import flatten\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from collections import Counter\n",
    "from nltk.lm import MLE, Laplace, KneserNeyInterpolated\n",
    "import pickle\n",
    "from os import linesep\n",
    "import json\n",
    "import collections\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "from operator import itemgetter\n",
    "import pytrec_eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99791a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of sentences is 4144\n",
      "The number of tokens is 101875\n",
      "The average number of tokens per sentence is 25\n",
      "The number of unique tokens are 13908\n"
     ]
    }
   ],
   "source": [
    "# Some interesting Corpus statistics\n",
    "from nltk import word_tokenize, sent_tokenize \n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "corpus = brown.words(categories='news')\n",
    "reconstructedSentence = TreebankWordDetokenizer().detokenize(corpus)\n",
    "\n",
    "sents = sent_tokenize(reconstructedSentence)\n",
    "print(\"The number of sentences is\", len(sents)) \n",
    "\n",
    "words = word_tokenize(reconstructedSentence)\n",
    "print(\"The number of tokens is\", len(words)) \n",
    "\n",
    "avg_tokens = round(len(words)/len(sents))\n",
    "print(\"The average number of tokens per sentence is\", avg_tokens) \n",
    "\n",
    "unique_tokens = set(words)\n",
    "print(\"The number of unique tokens are\", len(unique_tokens)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee0e16a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk.lm import MLE, Laplace, KneserNeyInterpolated\n",
    "\n",
    "# train model using Laplace smoothing\n",
    "def train_model(n, corpus):\n",
    "\n",
    "    train_, vocab_ = padded_everygram_pipeline(n, corpus)\n",
    "\n",
    "    lm = Laplace(n)\n",
    "    lm.fit(train_, vocab_)\n",
    "\n",
    "    save_model(lm, n)\n",
    "    return lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3fa3092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model for future reference\n",
    "\n",
    "def save_model(lm, n):\n",
    "  with open('%s_gram_model.pkl' % n, 'wb') as fout:\n",
    "    pickle.dump(lm, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4adc6fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean and load birbeck corpus\n",
    "\n",
    "def load_birbeck_corpus():\n",
    "\n",
    "  birbeck_list = dict()\n",
    "  f = open(\"C:\\\\Users\\\\vanam\\\\Downloads\\\\ota_20.500.12024_0643\\\\0643\\\\APPLING1DAT.643\", \"r\")\n",
    "  content = f.readlines()\n",
    "\n",
    "  for line in content:\n",
    "    if(line.startswith('$')):\n",
    "        continue\n",
    "    \n",
    "    pair = line.strip().split()\n",
    "    correct_word = pair[1].strip()\n",
    "    sentence = ' '.join(pair[2:]).split('*')[0].strip()\n",
    "\n",
    "    # print(sentence, \" : \", correct_word)\n",
    "    birbeck_list[sentence] = correct_word\n",
    "  return birbeck_list\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "318a767f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score the probability of a word in the given context \n",
    "\n",
    "def score(n, vocabulary, birbeck_list):\n",
    "\n",
    "  with open('%s_gram_model.pkl' % n, 'rb') as fin:\n",
    "    lm = pickle.load(fin)\n",
    "\n",
    "  n_prob = collections.defaultdict(dict)\n",
    "  for line in birbeck_list.keys():\n",
    "    for word in vocabulary:\n",
    "        \n",
    "      temp = line.split()[-(n-1):]\n",
    "      if(len(temp) < n-1 ):\n",
    "        for i in range(n-len(temp)-1):\n",
    "            temp.insert(0,'<s>')\n",
    "\n",
    "      score = lm.score(word, temp)\n",
    "      n_prob[line][word] = score\n",
    "    n_prob[line] = dict(sorted(n_prob[line].items(), key=lambda item: item[1], reverse = True)[:10])\n",
    "\n",
    "\n",
    "  with open('score_%s_gram.json' % n, 'w') as fp:\n",
    "    json.dump(n_prob, fp, indent=2)\n",
    "  return n_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c73716fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# create dictionary from unique tokens in brown corpus\n",
    "def clean_dict(dictionary):\n",
    "  len(dictionary)\n",
    "  vocab = []\n",
    "  regexp = re.compile('^[^a-zA-Z]+')\n",
    "  for word in dictionary:\n",
    "    # if(word.startswith(\"[a-zA-Z]\")):\n",
    "    if ( regexp.search(word) or len(word) == 1 ):\n",
    "      continue\n",
    "    vocab.append(word.lower())\n",
    "\n",
    "  return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "724edbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dictionaries to store top k results k = {1, 5, 10} respectively and write to files in system\n",
    "from collections import OrderedDict\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "def sorted_dict_elements_evaluate(correct_dict, prob_n_gram, n):\n",
    "  \n",
    "    sort_dict_10 = collections.defaultdict(dict)\n",
    "    sort_dict_5 = collections.defaultdict(dict)\n",
    "    sort_dict_1 = collections.defaultdict(dict)\n",
    "\n",
    "    for i in prob_n_gram:\n",
    "        sort_dict_10[i] =  (OrderedDict(sorted( prob_n_gram[i].items(), key=itemgetter(1))[:10]))\n",
    "        sort_dict_5[i] =  (OrderedDict(sorted( prob_n_gram[i].items(), key=itemgetter(1))[:5]))\n",
    "        sort_dict_1[i] =  (OrderedDict(sorted( prob_n_gram[i].items(), key=itemgetter(1))[:1]))\n",
    "    with open('sort_dict_%s.json' % n, 'w') as fp:\n",
    "        json.dump(sort_dict_10, fp, indent=2)\n",
    "        json.dump(sort_dict_5, fp, indent=2)\n",
    "        json.dump(sort_dict_1, fp, indent=2)\n",
    "        \n",
    "        \n",
    "    evaluate(correct_dict, sort_dict_10, sort_dict_5, sort_dict_1, n )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5cb0105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary with correct results from birkbeck corpus\n",
    "def calculate_correct_dict(birbeck_list):\n",
    "    correct_dict = collections.defaultdict(dict)\n",
    "    for item in birbeck_list.keys():\n",
    "        correct_dict[item] = {birbeck_list[item] : 1}\n",
    "    return correct_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d32a1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating average using pytrec_eval \n",
    "\n",
    "import pytrec_eval\n",
    "\n",
    "def evaluate(correct_dict, sort_dict_10, sort_dict_5, sort_dict_1, n ):\n",
    "  \n",
    "  results = collections.defaultdict(dict)\n",
    "\n",
    "  for item in correct_dict:\n",
    "      results[item] = {}\n",
    "      \n",
    "      if(list(correct_dict[item].keys())[0] in sort_dict_1[item].keys()):\n",
    "          results[item][list(correct_dict[item])[0]] = 1\n",
    "      \n",
    "      for k in list(sort_dict_5[item].keys()):\n",
    "          if( k not in results[item].keys()):\n",
    "              results[item][k] = 1/5\n",
    "              \n",
    "      for k in list(sort_dict_10[item].keys()):\n",
    "          if( k not in results[item].keys()):\n",
    "              results[item][k] = 1/10  \n",
    "\n",
    "  evaluator = pytrec_eval.RelevanceEvaluator(correct_dict, {'success'})\n",
    "  res = evaluator.evaluate(results)\n",
    "  \n",
    "  print()\n",
    "  print(\"\\n********Results for {}-gram-model *********\".format(n))\n",
    "  for measure in sorted(list(res[list(res.keys())[0]].keys())):\n",
    "        print('average', measure, ': ', pytrec_eval.compute_aggregated_measure(measure, [query_measures[measure] for query_measures in res.values()]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14c48f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate method to train and score  \n",
    "def train_calculate(n, corpus, vocabulary, birbeck_list):\n",
    " \n",
    "  train_model(n, corpus)\n",
    "  prob_n_gram = score(n, vocabulary, birbeck_list)\n",
    " \n",
    "  return prob_n_gram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8d8f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('brown')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "24894720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "********Results for 1-gram-model *********\n",
      "average success_1 :  0.0\n",
      "average success_10 :  0.0\n",
      "average success_5 :  0.0\n",
      "\n",
      "\n",
      "********Results for 2-gram-model *********\n",
      "average success_1 :  0.0\n",
      "average success_10 :  0.007407407407407408\n",
      "average success_5 :  0.0\n",
      "\n",
      "\n",
      "********Results for 3-gram-model *********\n",
      "average success_1 :  0.0\n",
      "average success_10 :  0.022222222222222223\n",
      "average success_5 :  0.0\n",
      "\n",
      "\n",
      "********Results for 5-gram-model *********\n",
      "average success_1 :  0.0\n",
      "average success_10 :  0.007407407407407408\n",
      "average success_5 :  0.0\n",
      "\n",
      "\n",
      "********Results for 10-gram-model *********\n",
      "average success_1 :  0.0\n",
      "average success_10 :  0.007407407407407408\n",
      "average success_5 :  0.0\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "\n",
    "tokens = brown.words(categories='news')\n",
    "vocabulary = clean_dict(set(tokens))\n",
    "\n",
    "birbeck_list = load_birbeck_corpus()\n",
    "# print(birbeck_list)\n",
    "\n",
    "corpus = brown.sents(categories='news')\n",
    "correct_dict = calculate_correct_dict(birbeck_list)\n",
    "\n",
    "# print(prob_3_gram)\n",
    "\n",
    "n = 1\n",
    "prob_n_gram = train_calculate(n, corpus, vocabulary, birbeck_list)\n",
    "sorted_dict_elements_evaluate(correct_dict, prob_n_gram, n)\n",
    "\n",
    "n = 2\n",
    "prob_n_gram = train_calculate(n, corpus, vocabulary, birbeck_list)\n",
    "sorted_dict_elements_evaluate(correct_dict, prob_n_gram, n)\n",
    "\n",
    "n = 3\n",
    "prob_n_gram = train_calculate(n, corpus, vocabulary, birbeck_list)\n",
    "sorted_dict_elements_evaluate(correct_dict, prob_n_gram, n)\n",
    "\n",
    "n = 5\n",
    "prob_n_gram = train_calculate(n, corpus, vocabulary, birbeck_list)\n",
    "sorted_dict_elements_evaluate(correct_dict, prob_n_gram, n)\n",
    "\n",
    "n = 10\n",
    "prob_n_gram = train_calculate(n, corpus, vocabulary, birbeck_list)\n",
    "sorted_dict_elements_evaluate(correct_dict, prob_n_gram, n)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3e48e2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of probability distribution for 10-gram model:\n",
      "\n",
      "I  :  {'had': 0.0002772579191793166, 'think': 0.0002772579191793166, \"can't\": 0.0002079434393844874, 'am': 0.0002079434393844874, 'never': 0.0002079434393844874, 'can': 0.0001386289595896583, 'hope': 0.0001386289595896583, 'cannot': 0.0001386289595896583, 'could': 0.0001386289595896583, 'told': 0.0001386289595896583}\n"
     ]
    }
   ],
   "source": [
    "print(\"Example of probability distribution for 10-gram model:\\n\")\n",
    "print(list(prob_n_gram.keys())[10], \" : \", prob_n_gram[list(prob_n_gram.keys())[10]] )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
